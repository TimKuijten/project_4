{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup #맗ip install beautifulsoup4\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import re as re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pymysql\n",
    "import sqlalchemy as alch\n",
    "from getpass import getpass\n",
    "\n",
    "#import googletrans\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#import spacy\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_restaurant_data(start, end):\n",
    "    all_restaurant_data = []\n",
    "    for offset in range(start, end, 30):\n",
    "        #Every page shows 30 restaurants\n",
    "        url = f'https://www.tripadvisor.com/RestaurantSearch-g187497-oa{offset}-Barcelona_Catalonia.html#EATERY_LIST_CONTENTS'\n",
    "        # As tripadvisor recognized python and blocked it I had to use header User-Agent\n",
    "        html = requests.get(url, headers={'User-Agent': \"Mozilla/5.0\"})\n",
    "        soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "        \n",
    "        tags_name = soup.find_all(\"a\", class_=\"Lwqic Cj b\")\n",
    "        tags_website = [a.get('href') for a in soup.find_all(\"a\", class_=\"Lwqic Cj b\", href=True)]\n",
    "        amount_reviews = soup.find_all(\"span\", class_=\"IiChw\")\n",
    "        tags_rating = soup.find_all(\"svg\", class_=\"UctUV d H0\")\n",
    "        cuisine_type = soup.find_all(\"svg\", class_=\"SUszq\")\n",
    "\n",
    "        names = [i.getText().strip() for i in tags_name]\n",
    "        # As it is a ranking, the output is (rank. Name of restaurant), so we remove the numbers\n",
    "        names = [re.sub(r'^[^.]*\\.', '', name) for name in names]\n",
    "        website = [i for i in tags_website]    \n",
    "        reviews = [re.sub(r'\\D', '', i.getText().strip()) for i in amount_reviews]\n",
    "        ratings = [tag.get('aria-label')[:3] for tag in tags_rating]\n",
    "    \n",
    "\n",
    "    \n",
    "        # Zip to add all values in a tuple for each restaurant\n",
    "        rows = list(zip(names, website, reviews, ratings))\n",
    "        all_restaurant_data.extend(rows)\n",
    "        \n",
    "    df_ta = pd.DataFrame(all_restaurant_data, columns=['Name', 'Website', 'Reviews', 'Rating'])\n",
    "    return df_ta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants = get_all_restaurant_data(60,190)\n",
    "df_restaurants.to_csv('df_restaurants.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_restaurant_data(country, start, end):\n",
    "    # Define df_restaurants inside the function\n",
    "    df_restaurants = pd.read_csv('df_restaurants.csv')\n",
    "\n",
    "    restaurant_data = []\n",
    "    for i in range(len(df_restaurants)):\n",
    "        url = 'https://www.tripadvisor.{}/{}'.format(country, df_restaurants['Website'][i])\n",
    "        for offset in range(start, end, 10):\n",
    "            url = url.replace('Reviews', 'Reviews-or{}'.format(offset))\n",
    "            html = requests.get(url, headers={'User-Agent': \"Mozilla/5.0\"})\n",
    "            soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "            # Find the review text and rating\n",
    "            tag_review = soup.find_all(\"div\", class_=\"review-container\")\n",
    "            review = [i.find(\"p\", class_=\"partial_entry\").getText().strip() for i in tag_review]\n",
    "            rating = [int(i.find(\"span\", class_=re.compile(\"bubble_\\d+\"))[\"class\"][1][7:]) for i in tag_review]\n",
    "            restaurant_name_tag = soup.find('h1', {'data-test-target': 'top-info-header'})\n",
    "            if restaurant_name_tag is not None:\n",
    "                restaurant_name = restaurant_name_tag.text\n",
    "            else:\n",
    "                restaurant_name = np.nan\n",
    "\n",
    "            # Find the date of visit\n",
    "            tag_date = soup.find_all(\"div\", class_=\"prw_rup prw_reviews_stay_date_hsx\")\n",
    "            date = []\n",
    "            for i in tag_date:\n",
    "                date_span = i.find(\"span\", class_=\"stay_date_label\")\n",
    "                if date_span:\n",
    "                    date_value = date_span.next_sibling.strip()\n",
    "                else:\n",
    "                    date_value = np.nan\n",
    "                date.append(date_value)\n",
    "\n",
    "            # Extract language and restaurant information\n",
    "            language = country\n",
    "            #restaurant = df_restaurants['Name'][i]\n",
    "\n",
    "            # Zip to add all values in a tuple for each restaurant\n",
    "            rows = list(zip(review, rating, date, [language]*len(review), [restaurant_name]*len(review)))\n",
    "            restaurant_data.extend(rows)\n",
    "\n",
    "    df_ta = pd.DataFrame(restaurant_data, columns=['review', 'rating', 'date', 'language', 'restaurant'])\n",
    "    return df_ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = (get_restaurant_data('DE', 0, 15))\n",
    "df_de.to_csv('../csv/scraping/df_de.csv', index = False)\n",
    "df_de.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.tripadvisor.nl', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d11881068-Reviews-or10-or0-Teoric_Taverna_Gastronomica-Barcelona_Catalonia.html (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002077AE0D480>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dns_host, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    954\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 955\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[0;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    359\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000002077AE0D480>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.tripadvisor.nl', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d11881068-Reviews-or10-or0-Teoric_Taverna_Gastronomica-Barcelona_Catalonia.html (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002077AE0D480>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_nl \u001b[39m=\u001b[39m (get_restaurant_data(\u001b[39m'\u001b[39;49m\u001b[39mNL\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m15\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_nl\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m], keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_nl\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdf_nl.csv\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 8\u001b[0m in \u001b[0;36mget_restaurant_data\u001b[1;34m(country, start, end)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m offset \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start, end, \u001b[39m10\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     url \u001b[39m=\u001b[39m url\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mReviews\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mReviews-or\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(offset))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     html \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mUser-Agent\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mMozilla/5.0\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(html\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# Find the review text and rating\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.tripadvisor.nl', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d11881068-Reviews-or10-or0-Teoric_Taverna_Gastronomica-Barcelona_Catalonia.html (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002077AE0D480>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "\n",
    "df_nl = (get_restaurant_data('NL', 0, 15))\n",
    "df_nl.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_nl.to_csv('../csv/scraping/df_nl.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Een heel gezellig restaurantje, met een heel g...</td>\n",
       "      <td>50</td>\n",
       "      <td>februari 2023</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zalige burgers en een zeer leuke en vlotte bed...</td>\n",
       "      <td>50</td>\n",
       "      <td>februari 2023</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heel klein restaurantje met alleen hamburgers ...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Klein restaurant met enthousiaste eigenaar en ...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hierheen gegaan net als alle Tripadvisor foodi...</td>\n",
       "      <td>50</td>\n",
       "      <td>september 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Top adres lekkere tapas vriendelijke mensen we...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Klein, maar s칰per knus. Z ontzettend gastvrij...</td>\n",
       "      <td>50</td>\n",
       "      <td>juli 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Hele lekkere tapas, goeie wijnen en aardige en...</td>\n",
       "      <td>50</td>\n",
       "      <td>juni 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Klein maar erg fijn. Gastvrouw en kok snappen ...</td>\n",
       "      <td>50</td>\n",
       "      <td>juni 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Heerlijk gegeten bij dit kleine lokale Tapas r...</td>\n",
       "      <td>50</td>\n",
       "      <td>mei 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows 칑 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  rating  \\\n",
       "0    Een heel gezellig restaurantje, met een heel g...      50   \n",
       "1    Zalige burgers en een zeer leuke en vlotte bed...      50   \n",
       "2    Heel klein restaurantje met alleen hamburgers ...      50   \n",
       "3    Klein restaurant met enthousiaste eigenaar en ...      50   \n",
       "4    Hierheen gegaan net als alle Tripadvisor foodi...      50   \n",
       "..                                                 ...     ...   \n",
       "480  Top adres lekkere tapas vriendelijke mensen we...      50   \n",
       "481  Klein, maar s칰per knus. Z ontzettend gastvrij...      50   \n",
       "482  Hele lekkere tapas, goeie wijnen en aardige en...      50   \n",
       "483  Klein maar erg fijn. Gastvrouw en kok snappen ...      50   \n",
       "484  Heerlijk gegeten bij dit kleine lokale Tapas r...      50   \n",
       "\n",
       "               date language               restaurant  \n",
       "0     februari 2023       NL  La Gastronomica Burgers  \n",
       "1     februari 2023       NL  La Gastronomica Burgers  \n",
       "2      oktober 2022       NL  La Gastronomica Burgers  \n",
       "3      oktober 2022       NL  La Gastronomica Burgers  \n",
       "4    september 2022       NL  La Gastronomica Burgers  \n",
       "..              ...      ...                      ...  \n",
       "480    oktober 2022       NL             Bodega Oliva  \n",
       "481       juli 2022       NL             Bodega Oliva  \n",
       "482       juni 2022       NL             Bodega Oliva  \n",
       "483       juni 2022       NL             Bodega Oliva  \n",
       "484        mei 2022       NL             Bodega Oliva  \n",
       "\n",
       "[392 rows x 5 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es = (get_restaurant_data('ES', 0, 15))\n",
    "df_es.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_es.to_csv('../csv/scraping/df_es.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riqu칤simas burguers y como en casa!\\n\\nMuy bue...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La Gastron칩mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Las hamburguesas brutales, buenos precios y la...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La Gastron칩mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hamburguesas muy ricas, especialmente la de Co...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La Gastron칩mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gracias Joel por el trato q nos has dado! Hemo...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La Gastron칩mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>칈bamos sin rumbo con unas amigas buscando dond...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La Gastron칩mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Fuimos hace alg칰n tiempo, y siempre quisimos r...</td>\n",
       "      <td>50</td>\n",
       "      <td>abril de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Anema E Core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Me serv칤 una copa de sangr칤a con una cucaracha...</td>\n",
       "      <td>10</td>\n",
       "      <td>marzo de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Anema E Core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>De los mejores restaurantes de bsrcelona donde...</td>\n",
       "      <td>50</td>\n",
       "      <td>enero de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Anema E Core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Buena calidad de tapas con muy buen ambiente游눆 ...</td>\n",
       "      <td>50</td>\n",
       "      <td>septiembre de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>仇벓릠네 great experience in this beautiful bar wit...</td>\n",
       "      <td>50</td>\n",
       "      <td>agosto de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows 칑 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  rating  \\\n",
       "0    Riqu칤simas burguers y como en casa!\\n\\nMuy bue...      50   \n",
       "1    Las hamburguesas brutales, buenos precios y la...      50   \n",
       "2    Hamburguesas muy ricas, especialmente la de Co...      50   \n",
       "3    Gracias Joel por el trato q nos has dado! Hemo...      50   \n",
       "4    칈bamos sin rumbo con unas amigas buscando dond...      50   \n",
       "..                                                 ...     ...   \n",
       "567  Fuimos hace alg칰n tiempo, y siempre quisimos r...      50   \n",
       "568  Me serv칤 una copa de sangr칤a con una cucaracha...      10   \n",
       "569  De los mejores restaurantes de bsrcelona donde...      50   \n",
       "570  Buena calidad de tapas con muy buen ambiente游눆 ...      50   \n",
       "571  仇벓릠네 great experience in this beautiful bar wit...      50   \n",
       "\n",
       "                   date language               restaurant  \n",
       "0       febrero de 2023       ES  La Gastron칩mica Burgers  \n",
       "1       febrero de 2023       ES  La Gastron칩mica Burgers  \n",
       "2       febrero de 2023       ES  La Gastron칩mica Burgers  \n",
       "3       febrero de 2023       ES  La Gastron칩mica Burgers  \n",
       "4       febrero de 2023       ES  La Gastron칩mica Burgers  \n",
       "..                  ...      ...                      ...  \n",
       "567       abril de 2022       ES             Anema E Core  \n",
       "568       marzo de 2022       ES             Anema E Core  \n",
       "569       enero de 2022       ES             Anema E Core  \n",
       "570  septiembre de 2022       ES             Bodega Oliva  \n",
       "571      agosto de 2022       ES             Bodega Oliva  \n",
       "\n",
       "[572 rows x 5 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_it = (get_restaurant_data('IT', 0, 15))\n",
    "df_it.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_it.to_csv('../csv/scraping/df_it.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr = (get_restaurant_data('FR', 0, 15))\n",
    "df_fr.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_fr.to_csv('../csv/scraping/df_fr.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_pt = (get_restaurant_data('PT', 0, 15))\n",
    "df_pt.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_pt.to_csv('../csv/scraping/df_pt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se = (get_restaurant_data('SE', 0, 15))\n",
    "df_se.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_se.to_csv('../csv/scraping/df_se.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no = (get_restaurant_data('NO', 0, 15))\n",
    "#df_no.drop_duplicates(subset=['review'])\n",
    "#df_no.to_csv('df_no.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fi = (get_restaurant_data('FI', 0, 15))\n",
    "#df_fi.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "#df_fi.to_csv('df_fi.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr = (get_restaurant_data('COM.GR', 0, 15))\n",
    "df_gr.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_gr.to_csv('../csv/scraping/df_gr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_cn = (get_restaurant_data('CN', 0, 15))\n",
    "#df_cn.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "#df_cn.to_csv('df_cn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = (get_restaurant_data('COM.TR', 0, 15))\n",
    "df_tr.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_tr.to_csv('../csv/scraping/df_tr.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ru = (get_restaurant_data('RU', 0, 15))\n",
    "df_ru.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_ru.to_csv('../csv/scraping/df_ru.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = (get_restaurant_data('COM', 0, 15))\n",
    "df_en.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_en.to_csv('../csv/scraping/df_en.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp = (get_restaurant_data('JP', 0, 15))\n",
    "df_jp.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_jp.to_csv('../csv/scraping/df_jp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_il = (get_restaurant_data('CO.IL', 0, 15))\n",
    "df_il.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_il.to_csv('../csv/scraping/df_l.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vn = (get_restaurant_data('COM.VN', 0, 15))\n",
    "df_vn.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_vn.to_csv('../csv/scraping/df_vn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kr = (get_restaurant_data('CO.KR', 0, 15))\n",
    "df_kr.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_kr.to_csv('../csv/scraping/df_kr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = (get_restaurant_data('IN', 0, 15))\n",
    "df_in.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_in.to_csv('../csv/scraping/df_in.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_languages.to_csv('df_all_languages.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_restaurant_data2(country, start, end):\n",
    "    # Define df_restaurants inside the function\n",
    "    df_restaurants = pd.read_csv('df_restaurants.csv')\n",
    "\n",
    "    restaurant_data = []\n",
    "    for i in range(len(df_restaurants)):\n",
    "        url = 'https://{}.tripadvisor.com/{}'.format(country, df_restaurants['Website'][i])\n",
    "        for offset in range(start, end, 10):\n",
    "            url = url.replace('Reviews', 'Reviews-or{}'.format(offset))\n",
    "            html = requests.get(url, headers={'User-Agent': \"Mozilla/5.0\"})\n",
    "            soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "            # Find the review text and rating\n",
    "            tag_review = soup.find_all(\"div\", class_=\"review-container\")\n",
    "            review = [i.find(\"p\", class_=\"partial_entry\").getText().strip() for i in tag_review]\n",
    "            rating = [int(i.find(\"span\", class_=re.compile(\"bubble_\\d+\"))[\"class\"][1][7:]) for i in tag_review]\n",
    "            restaurant_name_tag = soup.find('h1', {'data-test-target': 'top-info-header'})\n",
    "            if restaurant_name_tag is not None:\n",
    "                restaurant_name = restaurant_name_tag.text\n",
    "            else:\n",
    "                restaurant_name = np.nan\n",
    "\n",
    "            # Find the date of visit\n",
    "            tag_date = soup.find_all(\"div\", class_=\"prw_rup prw_reviews_stay_date_hsx\")\n",
    "            date = []\n",
    "            for i in tag_date:\n",
    "                date_span = i.find(\"span\", class_=\"stay_date_label\")\n",
    "                if date_span:\n",
    "                    date_value = date_span.next_sibling.strip()\n",
    "                else:\n",
    "                    date_value = np.nan\n",
    "                date.append(date_value)\n",
    "\n",
    "            # Extract language and restaurant information\n",
    "            language = country\n",
    "            #restaurant = df_restaurants['Name'][i]\n",
    "\n",
    "            # Zip to add all values in a tuple for each restaurant\n",
    "            rows = list(zip(review, rating, date, [language]*len(review), [restaurant_name]*len(review)))\n",
    "            restaurant_data.extend(rows)\n",
    "\n",
    "    df_ta = pd.DataFrame(restaurant_data, columns=['review', 'rating', 'date', 'language', 'restaurant'])\n",
    "    return df_ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no = (get_restaurant_data2('NO', 0, 15))\n",
    "df_no.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_no.to_csv('../csv/scraping/df_no.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = (get_restaurant_data2('ar', 0, 15))\n",
    "df_ar.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_ar.to_csv('../csv/scraping/df_ar.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_th = (get_restaurant_data2('TH', 0, 15))\n",
    "df_th.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_th.to_csv('../csv/scraping/df_th.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cn = (get_restaurant_data2('CN', 0, 15))\n",
    "df_cn.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_cn.to_csv('df_cn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_languages = pd.concat([df_all_languages3, df_de, df_es, df_fr, df_it, df_nl, df_pt, df_se, df_gr, df_tr, df_ru, df_en, df_jp, df_in, df_kr, df_vn, df_il, df_cn, df_th, df_ar, df_no], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_languages.to_csv('../csv/scraping/df_all_languages.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muss man mal gegessen haben. Die Burger sind f...</td>\n",
       "      <td>50</td>\n",
       "      <td>November 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traumhaft! H칬chste Qualit칛t und ein ganz tolle...</td>\n",
       "      <td>50</td>\n",
       "      <td>November 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die Burger haben alle unsere Erwartungen 칲bert...</td>\n",
       "      <td>50</td>\n",
       "      <td>November 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazing!! Einer der besten Burger die ich je h...</td>\n",
       "      <td>50</td>\n",
       "      <td>Oktober 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sehr leckere Burger zu erschwinglichen Preisen...</td>\n",
       "      <td>50</td>\n",
       "      <td>Oktober 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22910</th>\n",
       "      <td>Andre gang i Barcelona og kanskje 5 - 6 i denn...</td>\n",
       "      <td>50</td>\n",
       "      <td>april 2019</td>\n",
       "      <td>NO</td>\n",
       "      <td>Prado de Flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22911</th>\n",
       "      <td>Maten er veldig bra. Tjenesten er ogs친 veldig ...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2018</td>\n",
       "      <td>NO</td>\n",
       "      <td>Prado de Flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22912</th>\n",
       "      <td>Var ganske n칝r det viktigste turistomr친det s친 ...</td>\n",
       "      <td>40</td>\n",
       "      <td>august 2018</td>\n",
       "      <td>NO</td>\n",
       "      <td>Prado de Flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22913</th>\n",
       "      <td>God service, god mat og 칮l:). . . . . alle anb...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2018</td>\n",
       "      <td>NO</td>\n",
       "      <td>Prado de Flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22914</th>\n",
       "      <td>Mer</td>\n",
       "      <td>50</td>\n",
       "      <td>april 2021</td>\n",
       "      <td>NO</td>\n",
       "      <td>Anema E Core</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22915 rows 칑 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  \\\n",
       "0      Muss man mal gegessen haben. Die Burger sind f...      50   \n",
       "1      Traumhaft! H칬chste Qualit칛t und ein ganz tolle...      50   \n",
       "2      Die Burger haben alle unsere Erwartungen 칲bert...      50   \n",
       "3      Amazing!! Einer der besten Burger die ich je h...      50   \n",
       "4      Sehr leckere Burger zu erschwinglichen Preisen...      50   \n",
       "...                                                  ...     ...   \n",
       "22910  Andre gang i Barcelona og kanskje 5 - 6 i denn...      50   \n",
       "22911  Maten er veldig bra. Tjenesten er ogs친 veldig ...      50   \n",
       "22912  Var ganske n칝r det viktigste turistomr친det s친 ...      40   \n",
       "22913  God service, god mat og 칮l:). . . . . alle anb...      50   \n",
       "22914                                                Mer      50   \n",
       "\n",
       "                date language               restaurant  \n",
       "0      November 2022       DE  La Gastronomica Burgers  \n",
       "1      November 2022       DE  La Gastronomica Burgers  \n",
       "2      November 2022       DE  La Gastronomica Burgers  \n",
       "3       Oktober 2022       DE  La Gastronomica Burgers  \n",
       "4       Oktober 2022       DE  La Gastronomica Burgers  \n",
       "...              ...      ...                      ...  \n",
       "22910     april 2019       NO          Prado de Flores  \n",
       "22911   oktober 2018       NO          Prado de Flores  \n",
       "22912    august 2018       NO          Prado de Flores  \n",
       "22913   oktober 2018       NO          Prado de Flores  \n",
       "22914     april 2021       NO             Anema E Core  \n",
       "\n",
       "[22915 rows x 5 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fdc6fae217ca903371b404b170d56014636808a9a66a1f7d0100b88a428e005"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
