{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup #Â pip install beautifulsoup4\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import re as re\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pymysql\n",
    "import sqlalchemy as alch\n",
    "from getpass import getpass\n",
    "\n",
    "#import googletrans\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#import spacy\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_restaurant_data(start, end):\n",
    "    all_restaurant_data = []\n",
    "    for offset in range(start, end, 30):\n",
    "        #Every page shows 30 restaurants\n",
    "        url = f'https://www.tripadvisor.com/RestaurantSearch-g187497-oa{offset}-Barcelona_Catalonia.html#EATERY_LIST_CONTENTS'\n",
    "        # As tripadvisor recognized python and blocked it I had to use header User-Agent\n",
    "        html = requests.get(url, headers={'User-Agent': \"Mozilla/5.0\"})\n",
    "        soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "        \n",
    "        tags_name = soup.find_all(\"a\", class_=\"Lwqic Cj b\")\n",
    "        tags_website = [a.get('href') for a in soup.find_all(\"a\", class_=\"Lwqic Cj b\", href=True)]\n",
    "        amount_reviews = soup.find_all(\"span\", class_=\"IiChw\")\n",
    "        tags_rating = soup.find_all(\"svg\", class_=\"UctUV d H0\")\n",
    "        cuisine_type = soup.find_all(\"svg\", class_=\"SUszq\")\n",
    "\n",
    "        names = [i.getText().strip() for i in tags_name]\n",
    "        # As it is a ranking, the output is (rank. Name of restaurant), so we remove the numbers\n",
    "        names = [re.sub(r'^[^.]*\\.', '', name) for name in names]\n",
    "        website = [i for i in tags_website]    \n",
    "        reviews = [re.sub(r'\\D', '', i.getText().strip()) for i in amount_reviews]\n",
    "        ratings = [tag.get('aria-label')[:3] for tag in tags_rating]\n",
    "    \n",
    "\n",
    "    \n",
    "        # Zip to add all values in a tuple for each restaurant\n",
    "        rows = list(zip(names, website, reviews, ratings))\n",
    "        all_restaurant_data.extend(rows)\n",
    "        \n",
    "    df_ta = pd.DataFrame(all_restaurant_data, columns=['Name', 'Website', 'Reviews', 'Rating'])\n",
    "    return df_ta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restaurants = get_all_restaurant_data(60,190)\n",
    "df_restaurants.to_csv('df_restaurants.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_restaurant_data(country, start, end):\n",
    "    # Define df_restaurants inside the function\n",
    "    df_restaurants = pd.read_csv('df_restaurants.csv')\n",
    "\n",
    "    restaurant_data = []\n",
    "    for i in range(len(df_restaurants)):\n",
    "        url = 'https://www.tripadvisor.{}/{}'.format(country, df_restaurants['Website'][i])\n",
    "        for offset in range(start, end, 10):\n",
    "            url = url.replace('Reviews', 'Reviews-or{}'.format(offset))\n",
    "            html = requests.get(url, headers={'User-Agent': \"Mozilla/5.0\"})\n",
    "            soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "            # Find the review text and rating\n",
    "            tag_review = soup.find_all(\"div\", class_=\"review-container\")\n",
    "            review = [i.find(\"p\", class_=\"partial_entry\").getText().strip() for i in tag_review]\n",
    "            rating = [int(i.find(\"span\", class_=re.compile(\"bubble_\\d+\"))[\"class\"][1][7:]) for i in tag_review]\n",
    "            restaurant_name_tag = soup.find('h1', {'data-test-target': 'top-info-header'})\n",
    "            if restaurant_name_tag is not None:\n",
    "                restaurant_name = restaurant_name_tag.text\n",
    "            else:\n",
    "                restaurant_name = np.nan\n",
    "\n",
    "            # Find the date of visit\n",
    "            tag_date = soup.find_all(\"div\", class_=\"prw_rup prw_reviews_stay_date_hsx\")\n",
    "            date = []\n",
    "            for i in tag_date:\n",
    "                date_span = i.find(\"span\", class_=\"stay_date_label\")\n",
    "                if date_span:\n",
    "                    date_value = date_span.next_sibling.strip()\n",
    "                else:\n",
    "                    date_value = np.nan\n",
    "                date.append(date_value)\n",
    "\n",
    "            # Extract language and restaurant information\n",
    "            language = country\n",
    "            #restaurant = df_restaurants['Name'][i]\n",
    "\n",
    "            # Zip to add all values in a tuple for each restaurant\n",
    "            rows = list(zip(review, rating, date, [language]*len(review), [restaurant_name]*len(review)))\n",
    "            restaurant_data.extend(rows)\n",
    "\n",
    "    df_ta = pd.DataFrame(restaurant_data, columns=['review', 'rating', 'date', 'language', 'restaurant'])\n",
    "    return df_ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_de = (get_restaurant_data('DE', 0, 15))\n",
    "df_de.to_csv('df_de.csv', index = False)\n",
    "df_de.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='www.tripadvisor.nl', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d11881068-Reviews-or10-or0-Teoric_Taverna_Gastronomica-Barcelona_Catalonia.html (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002077AE0D480>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dns_host, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\util\\connection.py:72\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m six\u001b[39m.\u001b[39mraise_from(\n\u001b[0;32m     69\u001b[0m         LocationParseError(\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m host), \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[1;32m---> 72\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[0;32m     73\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    954\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 955\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[0;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    359\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFailed to establish a new connection: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[39mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000002077AE0D480>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.tripadvisor.nl', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d11881068-Reviews-or10-or0-Teoric_Taverna_Gastronomica-Barcelona_Catalonia.html (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002077AE0D480>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_nl \u001b[39m=\u001b[39m (get_restaurant_data(\u001b[39m'\u001b[39;49m\u001b[39mNL\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m15\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_nl\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m], keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_nl\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdf_nl.csv\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 8\u001b[0m in \u001b[0;36mget_restaurant_data\u001b[1;34m(country, start, end)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m offset \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start, end, \u001b[39m10\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     url \u001b[39m=\u001b[39m url\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mReviews\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mReviews-or\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(offset))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     html \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mUser-Agent\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mMozilla/5.0\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(html\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# Find the review text and rating\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\adapters.py:565\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    562\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    563\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    567\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='www.tripadvisor.nl', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d11881068-Reviews-or10-or0-Teoric_Taverna_Gastronomica-Barcelona_Catalonia.html (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002077AE0D480>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "\n",
    "df_nl = (get_restaurant_data('NL', 0, 15))\n",
    "df_nl.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_nl.to_csv('df_nl.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Een heel gezellig restaurantje, met een heel g...</td>\n",
       "      <td>50</td>\n",
       "      <td>februari 2023</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zalige burgers en een zeer leuke en vlotte bed...</td>\n",
       "      <td>50</td>\n",
       "      <td>februari 2023</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heel klein restaurantje met alleen hamburgers ...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Klein restaurant met enthousiaste eigenaar en ...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hierheen gegaan net als alle Tripadvisor foodi...</td>\n",
       "      <td>50</td>\n",
       "      <td>september 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Top adres lekkere tapas vriendelijke mensen we...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Klein, maar sÃºper knus. ZÃ² ontzettend gastvrij...</td>\n",
       "      <td>50</td>\n",
       "      <td>juli 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>Hele lekkere tapas, goeie wijnen en aardige en...</td>\n",
       "      <td>50</td>\n",
       "      <td>juni 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>Klein maar erg fijn. Gastvrouw en kok snappen ...</td>\n",
       "      <td>50</td>\n",
       "      <td>juni 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Heerlijk gegeten bij dit kleine lokale Tapas r...</td>\n",
       "      <td>50</td>\n",
       "      <td>mei 2022</td>\n",
       "      <td>NL</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  rating  \\\n",
       "0    Een heel gezellig restaurantje, met een heel g...      50   \n",
       "1    Zalige burgers en een zeer leuke en vlotte bed...      50   \n",
       "2    Heel klein restaurantje met alleen hamburgers ...      50   \n",
       "3    Klein restaurant met enthousiaste eigenaar en ...      50   \n",
       "4    Hierheen gegaan net als alle Tripadvisor foodi...      50   \n",
       "..                                                 ...     ...   \n",
       "480  Top adres lekkere tapas vriendelijke mensen we...      50   \n",
       "481  Klein, maar sÃºper knus. ZÃ² ontzettend gastvrij...      50   \n",
       "482  Hele lekkere tapas, goeie wijnen en aardige en...      50   \n",
       "483  Klein maar erg fijn. Gastvrouw en kok snappen ...      50   \n",
       "484  Heerlijk gegeten bij dit kleine lokale Tapas r...      50   \n",
       "\n",
       "               date language               restaurant  \n",
       "0     februari 2023       NL  La Gastronomica Burgers  \n",
       "1     februari 2023       NL  La Gastronomica Burgers  \n",
       "2      oktober 2022       NL  La Gastronomica Burgers  \n",
       "3      oktober 2022       NL  La Gastronomica Burgers  \n",
       "4    september 2022       NL  La Gastronomica Burgers  \n",
       "..              ...      ...                      ...  \n",
       "480    oktober 2022       NL             Bodega Oliva  \n",
       "481       juli 2022       NL             Bodega Oliva  \n",
       "482       juni 2022       NL             Bodega Oliva  \n",
       "483       juni 2022       NL             Bodega Oliva  \n",
       "484        mei 2022       NL             Bodega Oliva  \n",
       "\n",
       "[392 rows x 5 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es = (get_restaurant_data('ES', 0, 15))\n",
    "df_es.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_es.to_csv('df_es.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RiquÃ­simas burguers y como en casa!\\n\\nMuy bue...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La GastronÃ³mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Las hamburguesas brutales, buenos precios y la...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La GastronÃ³mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hamburguesas muy ricas, especialmente la de Co...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La GastronÃ³mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gracias Joel por el trato q nos has dado! Hemo...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La GastronÃ³mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ãbamos sin rumbo con unas amigas buscando dond...</td>\n",
       "      <td>50</td>\n",
       "      <td>febrero de 2023</td>\n",
       "      <td>ES</td>\n",
       "      <td>La GastronÃ³mica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>Fuimos hace algÃºn tiempo, y siempre quisimos r...</td>\n",
       "      <td>50</td>\n",
       "      <td>abril de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Anema E Core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>Me servÃ­ una copa de sangrÃ­a con una cucaracha...</td>\n",
       "      <td>10</td>\n",
       "      <td>marzo de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Anema E Core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>De los mejores restaurantes de bsrcelona donde...</td>\n",
       "      <td>50</td>\n",
       "      <td>enero de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Anema E Core</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Buena calidad de tapas con muy buen ambienteð ...</td>\n",
       "      <td>50</td>\n",
       "      <td>septiembre de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>â¤ðA great experience in this beautiful bar wit...</td>\n",
       "      <td>50</td>\n",
       "      <td>agosto de 2022</td>\n",
       "      <td>ES</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>572 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  rating  \\\n",
       "0    RiquÃ­simas burguers y como en casa!\\n\\nMuy bue...      50   \n",
       "1    Las hamburguesas brutales, buenos precios y la...      50   \n",
       "2    Hamburguesas muy ricas, especialmente la de Co...      50   \n",
       "3    Gracias Joel por el trato q nos has dado! Hemo...      50   \n",
       "4    Ãbamos sin rumbo con unas amigas buscando dond...      50   \n",
       "..                                                 ...     ...   \n",
       "567  Fuimos hace algÃºn tiempo, y siempre quisimos r...      50   \n",
       "568  Me servÃ­ una copa de sangrÃ­a con una cucaracha...      10   \n",
       "569  De los mejores restaurantes de bsrcelona donde...      50   \n",
       "570  Buena calidad de tapas con muy buen ambienteð ...      50   \n",
       "571  â¤ðA great experience in this beautiful bar wit...      50   \n",
       "\n",
       "                   date language               restaurant  \n",
       "0       febrero de 2023       ES  La GastronÃ³mica Burgers  \n",
       "1       febrero de 2023       ES  La GastronÃ³mica Burgers  \n",
       "2       febrero de 2023       ES  La GastronÃ³mica Burgers  \n",
       "3       febrero de 2023       ES  La GastronÃ³mica Burgers  \n",
       "4       febrero de 2023       ES  La GastronÃ³mica Burgers  \n",
       "..                  ...      ...                      ...  \n",
       "567       abril de 2022       ES             Anema E Core  \n",
       "568       marzo de 2022       ES             Anema E Core  \n",
       "569       enero de 2022       ES             Anema E Core  \n",
       "570  septiembre de 2022       ES             Bodega Oliva  \n",
       "571      agosto de 2022       ES             Bodega Oliva  \n",
       "\n",
       "[572 rows x 5 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_it = (get_restaurant_data('IT', 0, 15))\n",
    "df_it.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_it.to_csv('df_it.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr = (get_restaurant_data('FR', 0, 15))\n",
    "df_fr.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_fr.to_csv('df_fr.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_pt = (get_restaurant_data('PT', 0, 15))\n",
    "df_pt.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_pt.to_csv('df_pt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_se = (get_restaurant_data('SE', 0, 15))\n",
    "df_se.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_se.to_csv('df_se.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_no = (get_restaurant_data('NO', 0, 15))\n",
    "#df_no.drop_duplicates(subset=['review'])\n",
    "#df_no.to_csv('df_no.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_fi = (get_restaurant_data('FI', 0, 15))\n",
    "#df_fi.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "#df_fi.to_csv('df_fi.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Had a wonderful meal here! The best bit was th...</td>\n",
       "      <td>50</td>\n",
       "      <td>February 2023</td>\n",
       "      <td>FI</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Incredible burgers. The different kinds of mea...</td>\n",
       "      <td>50</td>\n",
       "      <td>February 2023</td>\n",
       "      <td>FI</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice burgers in a small setting (roughly a doz...</td>\n",
       "      <td>40</td>\n",
       "      <td>February 2023</td>\n",
       "      <td>FI</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'we had lot of burgers in my lifetime (and ha...</td>\n",
       "      <td>30</td>\n",
       "      <td>February 2023</td>\n",
       "      <td>FI</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good option if you are looking for a quality h...</td>\n",
       "      <td>50</td>\n",
       "      <td>February 2023</td>\n",
       "      <td>FI</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>Everything about this place is amazing! Defini...</td>\n",
       "      <td>50</td>\n",
       "      <td>January 2023</td>\n",
       "      <td>FI</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>What a lovely evening. My wife and I went for ...</td>\n",
       "      <td>50</td>\n",
       "      <td>January 2023</td>\n",
       "      <td>FI</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>Just a perfect evening! Everythnig was very go...</td>\n",
       "      <td>50</td>\n",
       "      <td>December 2022</td>\n",
       "      <td>FI</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Wow, what can I say.  An absolute wonderful ex...</td>\n",
       "      <td>50</td>\n",
       "      <td>December 2022</td>\n",
       "      <td>FI</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>After 5 days in Barcelona we luckily found thi...</td>\n",
       "      <td>50</td>\n",
       "      <td>December 2022</td>\n",
       "      <td>FI</td>\n",
       "      <td>Bodega Oliva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  rating           date  \\\n",
       "0    Had a wonderful meal here! The best bit was th...      50  February 2023   \n",
       "1    Incredible burgers. The different kinds of mea...      50  February 2023   \n",
       "2    Nice burgers in a small setting (roughly a doz...      40  February 2023   \n",
       "3    I'we had lot of burgers in my lifetime (and ha...      30  February 2023   \n",
       "4    Good option if you are looking for a quality h...      50  February 2023   \n",
       "..                                                 ...     ...            ...   \n",
       "872  Everything about this place is amazing! Defini...      50   January 2023   \n",
       "873  What a lovely evening. My wife and I went for ...      50   January 2023   \n",
       "874  Just a perfect evening! Everythnig was very go...      50  December 2022   \n",
       "875  Wow, what can I say.  An absolute wonderful ex...      50  December 2022   \n",
       "876  After 5 days in Barcelona we luckily found thi...      50  December 2022   \n",
       "\n",
       "    language               restaurant  \n",
       "0         FI  La Gastronomica Burgers  \n",
       "1         FI  La Gastronomica Burgers  \n",
       "2         FI  La Gastronomica Burgers  \n",
       "3         FI  La Gastronomica Burgers  \n",
       "4         FI  La Gastronomica Burgers  \n",
       "..       ...                      ...  \n",
       "872       FI             Bodega Oliva  \n",
       "873       FI             Bodega Oliva  \n",
       "874       FI             Bodega Oliva  \n",
       "875       FI             Bodega Oliva  \n",
       "876       FI             Bodega Oliva  \n",
       "\n",
       "[446 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr = (get_restaurant_data('COM.GR', 0, 15))\n",
    "df_gr.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_gr.to_csv('df_gr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectTimeout",
     "evalue": "HTTPSConnectionPool(host='www.tripadvisor.cn', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d25012128-Reviews-or10-or0-Xera_Restaurant-Barcelona_Catalonia.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020778787280>, 'Connection to www.tripadvisor.cn timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dns_host, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mgetaddrinfo returns an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[0;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[0;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[0;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    357\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[0;32m    359\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connection.py:179\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    180\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConnection to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m timed out. (connect timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout),\n\u001b[0;32m    183\u001b[0m     )\n\u001b[0;32m    185\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x0000020778787280>, 'Connection to www.tripadvisor.cn timed out. (connect timeout=None)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.tripadvisor.cn', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d25012128-Reviews-or10-or0-Xera_Restaurant-Barcelona_Catalonia.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020778787280>, 'Connection to www.tripadvisor.cn timed out. (connect timeout=None)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectTimeout\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_cn \u001b[39m=\u001b[39m (get_restaurant_data(\u001b[39m'\u001b[39;49m\u001b[39mCN\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m15\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_cn\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m], keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_cn\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mdf_cn.csv\u001b[39m\u001b[39m'\u001b[39m, index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 20\u001b[0m in \u001b[0;36mget_restaurant_data\u001b[1;34m(country, start, end)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m offset \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start, end, \u001b[39m10\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     url \u001b[39m=\u001b[39m url\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mReviews\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mReviews-or\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(offset))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     html \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mUser-Agent\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mMozilla/5.0\u001b[39;49m\u001b[39m\"\u001b[39;49m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(html\u001b[39m.\u001b[39mcontent, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# Find the review text and rating\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39m\u001b[39mget\u001b[39m\u001b[39m\"\u001b[39m, url, params\u001b[39m=\u001b[39mparams, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    585\u001b[0m }\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\requests\\adapters.py:553\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[0;32m    551\u001b[0m     \u001b[39m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n\u001b[0;32m    552\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, NewConnectionError):\n\u001b[1;32m--> 553\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    555\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ResponseError):\n\u001b[0;32m    556\u001b[0m     \u001b[39mraise\u001b[39;00m RetryError(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectTimeout\u001b[0m: HTTPSConnectionPool(host='www.tripadvisor.cn', port=443): Max retries exceeded with url: //Restaurant_Review-g187497-d25012128-Reviews-or10-or0-Xera_Restaurant-Barcelona_Catalonia.html (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000020778787280>, 'Connection to www.tripadvisor.cn timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "#df_cn = (get_restaurant_data('CN', 0, 15))\n",
    "#df_cn.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "#df_cn.to_csv('df_cn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr = (get_restaurant_data('COM.TR', 0, 15))\n",
    "df_tr.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_tr.to_csv('df_tr.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ru = (get_restaurant_data('RU', 0, 15))\n",
    "df_ru.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_ru.to_csv('df_ru.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en = (get_restaurant_data('COM', 0, 15))\n",
    "df_en.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_en.to_csv('df_en.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jp = (get_restaurant_data('JP', 0, 15))\n",
    "df_jp.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_jp.to_csv('df_jp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_il = (get_restaurant_data('CO.IL', 0, 15))\n",
    "df_il.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_il.to_csv('df_il.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vn = (get_restaurant_data('COM.VN', 0, 15))\n",
    "df_vn.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_vn.to_csv('df_vn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kr = (get_restaurant_data('CO.KR', 0, 15))\n",
    "df_kr.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_kr.to_csv('df_kr.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_in = (get_restaurant_data('IN', 0, 15))\n",
    "df_in.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_in.to_csv('df_in.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all_languages.to_csv('df_all_languages.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_restaurant_data2(country, start, end):\n",
    "    # Define df_restaurants inside the function\n",
    "    df_restaurants = pd.read_csv('df_restaurants.csv')\n",
    "\n",
    "    restaurant_data = []\n",
    "    for i in range(len(df_restaurants)):\n",
    "        url = 'https://{}.tripadvisor.com/{}'.format(country, df_restaurants['Website'][i])\n",
    "        for offset in range(start, end, 10):\n",
    "            url = url.replace('Reviews', 'Reviews-or{}'.format(offset))\n",
    "            html = requests.get(url, headers={'User-Agent': \"Mozilla/5.0\"})\n",
    "            soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "            # Find the review text and rating\n",
    "            tag_review = soup.find_all(\"div\", class_=\"review-container\")\n",
    "            review = [i.find(\"p\", class_=\"partial_entry\").getText().strip() for i in tag_review]\n",
    "            rating = [int(i.find(\"span\", class_=re.compile(\"bubble_\\d+\"))[\"class\"][1][7:]) for i in tag_review]\n",
    "            restaurant_name_tag = soup.find('h1', {'data-test-target': 'top-info-header'})\n",
    "            if restaurant_name_tag is not None:\n",
    "                restaurant_name = restaurant_name_tag.text\n",
    "            else:\n",
    "                restaurant_name = np.nan\n",
    "\n",
    "            # Find the date of visit\n",
    "            tag_date = soup.find_all(\"div\", class_=\"prw_rup prw_reviews_stay_date_hsx\")\n",
    "            date = []\n",
    "            for i in tag_date:\n",
    "                date_span = i.find(\"span\", class_=\"stay_date_label\")\n",
    "                if date_span:\n",
    "                    date_value = date_span.next_sibling.strip()\n",
    "                else:\n",
    "                    date_value = np.nan\n",
    "                date.append(date_value)\n",
    "\n",
    "            # Extract language and restaurant information\n",
    "            language = country\n",
    "            #restaurant = df_restaurants['Name'][i]\n",
    "\n",
    "            # Zip to add all values in a tuple for each restaurant\n",
    "            rows = list(zip(review, rating, date, [language]*len(review), [restaurant_name]*len(review)))\n",
    "            restaurant_data.extend(rows)\n",
    "\n",
    "    df_ta = pd.DataFrame(restaurant_data, columns=['review', 'rating', 'date', 'language', 'restaurant'])\n",
    "    return df_ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no = (get_restaurant_data2('NO', 0, 15))\n",
    "df_no.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_no.to_csv('df_no.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ar = (get_restaurant_data2('ar', 0, 15))\n",
    "df_ar.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_ar.to_csv('df_ar.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_th = (get_restaurant_data2('TH', 0, 15))\n",
    "df_th.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_th.to_csv('df_th.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cn = (get_restaurant_data2('CN', 0, 15))\n",
    "df_cn.drop_duplicates(subset=['review', 'date'], keep='first', inplace=True)\n",
    "df_cn.to_csv('df_cn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_languages = pd.concat([df_all_languages3, df_de, df_es, df_fr, df_it, df_nl, df_pt, df_se, df_gr, df_tr, df_ru, df_en, df_jp, df_in, df_kr, df_vn, df_il, df_cn, df_th, df_ar, df_no], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_languages.to_csv('df_all_languages.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muss man mal gegessen haben. Die Burger sind f...</td>\n",
       "      <td>50</td>\n",
       "      <td>November 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traumhaft! HÃ¶chste QualitÃ¤t und ein ganz tolle...</td>\n",
       "      <td>50</td>\n",
       "      <td>November 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die Burger haben alle unsere Erwartungen Ã¼bert...</td>\n",
       "      <td>50</td>\n",
       "      <td>November 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazing!! Einer der besten Burger die ich je h...</td>\n",
       "      <td>50</td>\n",
       "      <td>Oktober 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sehr leckere Burger zu erschwinglichen Preisen...</td>\n",
       "      <td>50</td>\n",
       "      <td>Oktober 2022</td>\n",
       "      <td>DE</td>\n",
       "      <td>La Gastronomica Burgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22910</th>\n",
       "      <td>Andre gang i Barcelona og kanskje 5 - 6 i denn...</td>\n",
       "      <td>50</td>\n",
       "      <td>april 2019</td>\n",
       "      <td>NO</td>\n",
       "      <td>Prado de Flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22911</th>\n",
       "      <td>Maten er veldig bra. Tjenesten er ogsÃ¥ veldig ...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2018</td>\n",
       "      <td>NO</td>\n",
       "      <td>Prado de Flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22912</th>\n",
       "      <td>Var ganske nÃ¦r det viktigste turistomrÃ¥det sÃ¥ ...</td>\n",
       "      <td>40</td>\n",
       "      <td>august 2018</td>\n",
       "      <td>NO</td>\n",
       "      <td>Prado de Flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22913</th>\n",
       "      <td>God service, god mat og Ã¸l:). . . . . alle anb...</td>\n",
       "      <td>50</td>\n",
       "      <td>oktober 2018</td>\n",
       "      <td>NO</td>\n",
       "      <td>Prado de Flores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22914</th>\n",
       "      <td>Mer</td>\n",
       "      <td>50</td>\n",
       "      <td>april 2021</td>\n",
       "      <td>NO</td>\n",
       "      <td>Anema E Core</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22915 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  \\\n",
       "0      Muss man mal gegessen haben. Die Burger sind f...      50   \n",
       "1      Traumhaft! HÃ¶chste QualitÃ¤t und ein ganz tolle...      50   \n",
       "2      Die Burger haben alle unsere Erwartungen Ã¼bert...      50   \n",
       "3      Amazing!! Einer der besten Burger die ich je h...      50   \n",
       "4      Sehr leckere Burger zu erschwinglichen Preisen...      50   \n",
       "...                                                  ...     ...   \n",
       "22910  Andre gang i Barcelona og kanskje 5 - 6 i denn...      50   \n",
       "22911  Maten er veldig bra. Tjenesten er ogsÃ¥ veldig ...      50   \n",
       "22912  Var ganske nÃ¦r det viktigste turistomrÃ¥det sÃ¥ ...      40   \n",
       "22913  God service, god mat og Ã¸l:). . . . . alle anb...      50   \n",
       "22914                                                Mer      50   \n",
       "\n",
       "                date language               restaurant  \n",
       "0      November 2022       DE  La Gastronomica Burgers  \n",
       "1      November 2022       DE  La Gastronomica Burgers  \n",
       "2      November 2022       DE  La Gastronomica Burgers  \n",
       "3       Oktober 2022       DE  La Gastronomica Burgers  \n",
       "4       Oktober 2022       DE  La Gastronomica Burgers  \n",
       "...              ...      ...                      ...  \n",
       "22910     april 2019       NO          Prado de Flores  \n",
       "22911   oktober 2018       NO          Prado de Flores  \n",
       "22912    august 2018       NO          Prado de Flores  \n",
       "22913   oktober 2018       NO          Prado de Flores  \n",
       "22914     april 2021       NO             Anema E Core  \n",
       "\n",
       "[22915 rows x 5 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W5sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W5sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(html, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W5sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m feed \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39;49mfind_all(\u001b[39m\"\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m\"\u001b[39;49m, {\u001b[39m\"\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m\"\u001b[39;49m:\u001b[39m\"\u001b[39;49m\u001b[39mratings_and_types block_wrap ui_section\u001b[39;49m\u001b[39m\"\u001b[39;49m})[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W5sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m posts \u001b[39m=\u001b[39m feed\u001b[39m.\u001b[39mfind_all(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mui_column is-9\u001b[39m\u001b[39m\"\u001b[39m})\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "url = \"https://www.tripadvisor.com/Restaurant_Review-g187497-d12702677-Reviews-La_Gastronomica_Burgers-Barcelona_Catalonia.html\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the \"I Accept\" button to load\n",
    "WebDriverWait(driver, 90).until(\n",
    "    EC.presence_of_element_located((By.ID, \"onetrust-button-group\"))\n",
    ")\n",
    "\n",
    "# Click the \"I Accept\" button\n",
    "accept_button = driver.find_element(By.ID, \"onetrust-accept-btn-handler\")\n",
    "accept_button.click()\n",
    "\n",
    "# Click the \"More languages\" button\n",
    "more_languages = WebDriverWait(driver, 3).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//div[@class='taLnk' and span[text()='More languages']]\"))\n",
    ")\n",
    "\n",
    "# Wait for 5 seconds\n",
    "time.sleep(5)\n",
    "\n",
    "# Click the \"More languages\" element\n",
    "more_languages.click()\n",
    "\n",
    "# Wait for the \"Dutch\" button element to be clickable\n",
    "dutch_language = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, \"label[for='filters_detail_language_filterLang_nl']\"))\n",
    ")\n",
    "\n",
    "# Click the \"Dutch\" button element\n",
    "dutch_language.click()\n",
    "\n",
    "html = ''\n",
    "while True:\n",
    "    try:\n",
    "        # Wait for the \"Next\" button element to be clickable\n",
    "        next_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \".pagination .nav.next\"))\n",
    "        )\n",
    "    except:\n",
    "        break\n",
    "\n",
    "    # Click the next button\n",
    "    next_button.click()\n",
    "\n",
    "    # Wait for the reviews to load\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \".review-container\"))\n",
    "    )\n",
    "\n",
    "    # Get the HTML content of the current page\n",
    "    html += driver.execute_script(\"return document.documentElement.outerHTML\")\n",
    "\n",
    "    # Check if the next button is disabled\n",
    "    if \"disabled\" in next_button.get_attribute(\"class\"):\n",
    "        break\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "feed = soup.find_all(\"div\", {\"class\":\"ratings_and_types block_wrap ui_section\"})[0]\n",
    "posts = feed.find_all(\"div\", {\"class\":\"ui_column is-9\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W6sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     next_button\u001b[39m.\u001b[39;49mclick()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:93\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(Command\u001b[39m.\u001b[39;49mCLICK_ELEMENT)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:403\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    402\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[1;32m--> 403\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\Tim_K\\miniconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <a class=\"nav next ui_button primary disabled\">...</a> is not clickable at point (595, 457). Other element would receive the click: <div class=\"unified ui_pagination \">...</div>\n  (Session info: chrome=110.0.5481.177)\nStacktrace:\nBacktrace:\n\t(No symbol) [0x00D437D3]\n\t(No symbol) [0x00CD8B81]\n\t(No symbol) [0x00BDB36D]\n\t(No symbol) [0x00C14E3B]\n\t(No symbol) [0x00C126DB]\n\t(No symbol) [0x00C0FD0B]\n\t(No symbol) [0x00C0E4D8]\n\t(No symbol) [0x00C03253]\n\t(No symbol) [0x00C2B41C]\n\t(No symbol) [0x00C02B96]\n\t(No symbol) [0x00C2B774]\n\t(No symbol) [0x00C41215]\n\t(No symbol) [0x00C2B216]\n\t(No symbol) [0x00C00D97]\n\t(No symbol) [0x00C0253D]\n\tGetHandleVerifier [0x00FBABF2+2510930]\n\tGetHandleVerifier [0x00FE8EC1+2700065]\n\tGetHandleVerifier [0x00FEC86C+2714828]\n\tGetHandleVerifier [0x00DF3480+645344]\n\t(No symbol) [0x00CE0FD2]\n\t(No symbol) [0x00CE6C68]\n\t(No symbol) [0x00CE6D4B]\n\t(No symbol) [0x00CF0D6B]\n\tBaseThreadInitThunk [0x76FB00F9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77837BBE+286]\n\tRtlGetAppContainerNamedObjectPath [0x77837B8E+238]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Tim_K\\Ironhack\\project-4\\webscrape.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W6sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W6sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m             time\u001b[39m.\u001b[39;49msleep(\u001b[39m3\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W6sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Tim_K/Ironhack/project-4/webscrape.ipynb#W6sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(html), \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "html = []\n",
    "\n",
    "url = \"https://www.tripadvisor.com/Restaurant_Review-g187497-d12702677-Reviews-La_Gastronomica_Burgers-Barcelona_Catalonia.html\"\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the \"I Accept\" button to load\n",
    "WebDriverWait(driver, 90).until(\n",
    "    EC.presence_of_element_located((By.ID, \"onetrust-button-group\"))\n",
    ")\n",
    "\n",
    "# Click the \"I Accept\" button\n",
    "accept_button = driver.find_element(By.ID, \"onetrust-accept-btn-handler\")\n",
    "accept_button.click()\n",
    "\n",
    "# Click the \"More languages\" button\n",
    "more_languages = WebDriverWait(driver, 3).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"//div[@class='taLnk' and span[text()='More languages']]\"))\n",
    ")\n",
    "\n",
    "# Wait for 5 seconds\n",
    "time.sleep(5)\n",
    "\n",
    "# Click the \"More languages\" element\n",
    "more_languages.click()\n",
    "\n",
    "# Wait for the \"Dutch\" button element to be clickable\n",
    "dutch_language = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.CSS_SELECTOR, \"label[for='filters_detail_language_filterLang_nl']\"))\n",
    ")\n",
    "\n",
    "# Click the \"Dutch\" button element\n",
    "dutch_language.click()\n",
    "\n",
    "while True:\n",
    "    # Wait for the \"Next\" button element to be clickable\n",
    "    next_button = None\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            next_button = WebDriverWait(driver, 3).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, 'nav.next'))\n",
    "            )\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "            \n",
    "    if next_button is None:\n",
    "        break\n",
    "        \n",
    "    # Append the current page HTML to the list\n",
    "    html.append(driver.execute_script(\"return document.documentElement.outerHTML;\"))\n",
    "    \n",
    "    # Click the next button\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            next_button.click()\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "            continue\n",
    "        \n",
    "soup = BeautifulSoup(''.join(html), \"html.parser\")\n",
    "feed = soup.find_all(\"div\", {\"class\":\"ratings_and_types block_wrap ui_section\"})[0]\n",
    "posts = feed.find_all(\"div\", {\"class\":\"ui_column is-9\"})\n",
    "\n",
    "with open(\"reviews.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(soup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n",
      "C:\\Users\\Tim_K\\AppData\\Local\\Temp\\ipykernel_11784\\2510392009.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Reviews_Dutch = Reviews_Dutch.append({\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "Reviews_Dutch = pd.DataFrame(columns=['Rating', 'Date', 'Restaurant', 'Review_1'])\n",
    "\n",
    "for post in posts:\n",
    "    # Extract the Rating\n",
    "    rating = re.search(r'bubble_(\\d{2})', str(post)).group(1)\n",
    "    \n",
    "    # Extract the Date\n",
    "    date = re.search(r'title=\"(.+?)\"', str(post)).group(1)\n",
    "    \n",
    "    # Extract the Restaurant\n",
    "    restaurant = re.search(r'href=\"/(.+?)\"', str(post)).group(1)\n",
    "\n",
    "    review = re.search(r'partial_entry\">(.*?)\"', str(post))\n",
    "    \n",
    "    # Define the regex pattern to search for the review text\n",
    "    #pattern = r'partial_entry\">(.*?)</span></p></div></div>'\n",
    "\n",
    "    # Search for the review text using the regex pattern and save it to a new column in the dataframe\n",
    "    #Reviews_Dutch['Review_1'] = Reviews_Dutch['Review_1'].apply(lambda x: re.search(pattern, x, re.DOTALL).group(1))\n",
    "\n",
    "    \n",
    "    Reviews_Dutch = Reviews_Dutch.append({\n",
    "        'Rating': rating,\n",
    "        'Date': date,\n",
    "        'Restaurant': restaurant,\n",
    "        'Review': review,  \n",
    "    }, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Review_1</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>August 23, 2019</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r702255865-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>June 13, 2019</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r681209861-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1039, 1202), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>June 5, 2019</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r679288926-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1050, 1196), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>May 14, 2019</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r674081201-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1193, 1328), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>March 23, 2019</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r660584032-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>February 2, 2019</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r649643958-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1200, 1343), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>January 25, 2019</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r648201313-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1195, 1344), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>August 27, 2018</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r610822696-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1195, 1345), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>July 12, 2018</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r595680805-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>June 12, 2018</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r587014463-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>May 27, 2018</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r582996249-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1191, 1340), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>May 26, 2018</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r582893763-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>April 19, 2018</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r574348308-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1189, 1347), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>November 1, 2017</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r537714534-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1205, 1333), match='pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>November 1, 2017</td>\n",
       "      <td>ShowUserReviews-g187497-d12702677-r537712343-L...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;re.Match object; span=(1192, 1351), match='pa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating              Date  \\\n",
       "0      50   August 23, 2019   \n",
       "1      50     June 13, 2019   \n",
       "2      50      June 5, 2019   \n",
       "3      50      May 14, 2019   \n",
       "4      50    March 23, 2019   \n",
       "5      50  February 2, 2019   \n",
       "6      50  January 25, 2019   \n",
       "7      50   August 27, 2018   \n",
       "8      50     July 12, 2018   \n",
       "9      50     June 12, 2018   \n",
       "10     30      May 27, 2018   \n",
       "11     30      May 26, 2018   \n",
       "12     50    April 19, 2018   \n",
       "13     50  November 1, 2017   \n",
       "14     40  November 1, 2017   \n",
       "\n",
       "                                           Restaurant Review_1  \\\n",
       "0   ShowUserReviews-g187497-d12702677-r702255865-L...      NaN   \n",
       "1   ShowUserReviews-g187497-d12702677-r681209861-L...      NaN   \n",
       "2   ShowUserReviews-g187497-d12702677-r679288926-L...      NaN   \n",
       "3   ShowUserReviews-g187497-d12702677-r674081201-L...      NaN   \n",
       "4   ShowUserReviews-g187497-d12702677-r660584032-L...      NaN   \n",
       "5   ShowUserReviews-g187497-d12702677-r649643958-L...      NaN   \n",
       "6   ShowUserReviews-g187497-d12702677-r648201313-L...      NaN   \n",
       "7   ShowUserReviews-g187497-d12702677-r610822696-L...      NaN   \n",
       "8   ShowUserReviews-g187497-d12702677-r595680805-L...      NaN   \n",
       "9   ShowUserReviews-g187497-d12702677-r587014463-L...      NaN   \n",
       "10  ShowUserReviews-g187497-d12702677-r582996249-L...      NaN   \n",
       "11  ShowUserReviews-g187497-d12702677-r582893763-L...      NaN   \n",
       "12  ShowUserReviews-g187497-d12702677-r574348308-L...      NaN   \n",
       "13  ShowUserReviews-g187497-d12702677-r537714534-L...      NaN   \n",
       "14  ShowUserReviews-g187497-d12702677-r537712343-L...      NaN   \n",
       "\n",
       "                                               Review  \n",
       "0                                                None  \n",
       "1   <re.Match object; span=(1039, 1202), match='pa...  \n",
       "2   <re.Match object; span=(1050, 1196), match='pa...  \n",
       "3   <re.Match object; span=(1193, 1328), match='pa...  \n",
       "4                                                None  \n",
       "5   <re.Match object; span=(1200, 1343), match='pa...  \n",
       "6   <re.Match object; span=(1195, 1344), match='pa...  \n",
       "7   <re.Match object; span=(1195, 1345), match='pa...  \n",
       "8                                                None  \n",
       "9                                                None  \n",
       "10  <re.Match object; span=(1191, 1340), match='pa...  \n",
       "11                                               None  \n",
       "12  <re.Match object; span=(1189, 1347), match='pa...  \n",
       "13  <re.Match object; span=(1205, 1333), match='pa...  \n",
       "14  <re.Match object; span=(1192, 1351), match='pa...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reviews_Dutch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.10.8)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "posts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.10.8)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fdc6fae217ca903371b404b170d56014636808a9a66a1f7d0100b88a428e005"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
